{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1v98T50c4_0HwNx7sNTh5wKly0jlvEMYo",
      "authorship_tag": "ABX9TyPCei6QAL/UNVrhEeIRI4SN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakarla/AI-in-the-Built-Environment/blob/main/week%204_5_Data%20Visualization/Notebook%20code/Clustring_CSV_SOM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, you will learn how to apply the clustring algorithm on the image dataset.\n",
        "\n",
        "This is a pipeline of our work:\n",
        "\n",
        "1.  **Introduction to SOMs:** Provide a brief overview of what SOMs are and how they are used in machine learning.\n",
        "2. **Environment Setup:** Instructions on installing necessary libraries.\n",
        "3.  **Data Loading:** How to load data from a CSV file.\n",
        "4.  **Data Preprocessing:** Preparing image data for training.\n",
        "5.  **Training the SOM:** Setting up and training the SOM on image data.\n",
        "6.  **Visualization:** Visualizing the results.\n",
        "7.  **Conclusion:** Summarize what was learned."
      ],
      "metadata": {
        "id": "6jKttD5dim-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step1:** First you need to create the csv file if you have not.\n",
        "\n",
        "If you have CSV file do not run this cells.\n",
        "\n",
        "This code make a csv file from all images we have. Every row in this file is feature extracted from an image."
      ],
      "metadata": {
        "id": "fsGWRBiKO1d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "def load_and_preprocess_image(image_path, size=(224, 224)):\n",
        "    try:\n",
        "        # Load the image\n",
        "        img = Image.open(image_path).convert('RGB')  # Ensure the image is in RGB format\n",
        "        # Resize the image\n",
        "        img = img.resize(size)\n",
        "        # Convert the image to an array\n",
        "        img_array = img_to_array(img)\n",
        "        # Expand dimensions to match the shape required by VGG16\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        # Preprocess the image for VGG16\n",
        "        img_array = preprocess_input(img_array)\n",
        "        return img_array\n",
        "    except Exception as e:\n",
        "        print(f\"Cannot process image: {image_path}, Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def save_to_csv(data, filename):\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    # Save to CSV\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "#########################################################\n",
        "# Directory where your images are stored\n",
        "image_dir = '/content/drive/MyDrive/Colab Notebooks/streetview'\n",
        "\n",
        "#########################################################\n",
        "image_paths = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.jpg')]\n",
        "# Load the VGG16 model pre-trained on ImageNet\n",
        "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "def extract_features(image_paths, model):\n",
        "    features = []\n",
        "    for path in image_paths:\n",
        "        img_array = load_and_preprocess_image(path)\n",
        "        if img_array is not None:\n",
        "            try:\n",
        "                # Extract features using VGG16\n",
        "                feature = model.predict(img_array)\n",
        "                # Flatten the feature map\n",
        "                feature = feature.flatten()\n",
        "                features.append({'FileName': os.path.basename(path), 'Features': feature.tolist()})\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting features from image: {path}, Error: {e}\")\n",
        "    return features\n",
        "\n",
        "# Extract features for all images\n",
        "image_features = extract_features(image_paths, vgg16_model)\n",
        "\n",
        "#########################################################\n",
        "# Save the features to CSV\n",
        "save_to_csv(image_features, '/content/drive/MyDrive/Colab Notebooks/image_features_vgg16_strretview.csv')\n",
        "\n",
        "#########################################################"
      ],
      "metadata": {
        "id": "crherkFoqYtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup\n",
        "\n",
        "Please run the below cell to install necessary libraries if they are not already installed.\n"
      ],
      "metadata": {
        "id": "3qpLteZ_j4Sz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XUHgHPEQjpw"
      },
      "outputs": [],
      "source": [
        "!pip install numpy pandas matplotlib minisom\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data\n",
        "\n",
        "We will load our dataset of images from a CSV file. Each row in the CSV represents an image.\n"
      ],
      "metadata": {
        "id": "RcSToIBDkBBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y6dUDZDEkfUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "We need to convert the feature strings back into numerical format and normalize the data.\n"
      ],
      "metadata": {
        "id": "NEyHsSpAli-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from minisom import MiniSom\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "############################################################################################\n",
        "# Load the CSV file\n",
        "csv_file_path = '/content/drive/MyDrive/Colab Notebooks/image_features_vgg16_strretview.csv'\n",
        "############################################################################################\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Extract filenames and convert stringified lists to actual lists\n",
        "filenames = data.iloc[:, 0].values\n",
        "features = data.iloc[:, 1].apply(ast.literal_eval).tolist()\n",
        "features = np.array(features)\n"
      ],
      "metadata": {
        "id": "dRbBJT_rJtUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the SOM\n",
        "\n",
        "First of all, we need to set up some hyperparameters. you can change each of them to see the result."
      ],
      "metadata": {
        "id": "OYd1QeXfr_PE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters for SOM\n",
        "m = 10\n",
        "map_size = (m, m)\n",
        "input_len = features.shape[1]\n",
        "sigma = 1.0\n",
        "learning_rate = 0.5\n",
        "num_epochs = 1000"
      ],
      "metadata": {
        "id": "jWRVtQv9JsHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now initialize and train our SOM on the preprocessed image features."
      ],
      "metadata": {
        "id": "Jn2vOKbRKR5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize SOM\n",
        "som = MiniSom(map_size[0], map_size[1], input_len, sigma=sigma, learning_rate=learning_rate,\n",
        "              activation_distance='cosine', random_seed=42)\n",
        "# som.pca_weights_init(features)\n",
        "som.random_weights_init(features)\n",
        "# train SOM\n",
        "som.train_random(features, len(features), verbose=True)\n",
        "# determine best matching units for each image\n",
        "bmu_indices = np.array([som.winner(x) for x in features])"
      ],
      "metadata": {
        "id": "RPtW510RKa6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization of SOM Results\n",
        "\n",
        "Let's visualize the SOM and annotate the images with their respective indices.\n"
      ],
      "metadata": {
        "id": "gK9JpqPqsFqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with 10x10 subplots\n",
        "dpi = 100\n",
        "subplot_size = 224\n",
        "figsize = (m * subplot_size / dpi, m * subplot_size / dpi)\n",
        "\n",
        "# Create a figure with 10x10 subplots\n",
        "fig, axes = plt.subplots(m, m, figsize=figsize)\n",
        "\n",
        "# Create a list to keep track of cluster sizes\n",
        "cluster_sizes = []\n",
        "\n",
        "# Plot each image in the 10x10 grid\n",
        "for i in range(m):\n",
        "    for j in range(m):\n",
        "        # Get the index of the image to plot\n",
        "        index = i * m + j\n",
        "        bmu_images = filenames[(bmu_indices[:, 0] == i) & (bmu_indices[:, 1] == j)]\n",
        "\n",
        "        # Append cluster size to the list\n",
        "        cluster_sizes.append(len(bmu_images))\n",
        "\n",
        "        # Plot the first image in the cluster (you can customize this)\n",
        "        if len(bmu_images) > 0:\n",
        "            try:\n",
        "              ###############################################################################################\n",
        "                img = Image.open('/content/drive/MyDrive/Colab Notebooks/streetview/' + bmu_images[0])\n",
        "              ###############################################################################################\n",
        "                axes[i, j].imshow(img)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {bmu_images[0]}: {e}\")\n",
        "                axes[i, j].text(0.5, 0.5, \"Error\", ha=\"center\", va=\"center\")\n",
        "        else:\n",
        "            # In case of empty clusters, you can display a placeholder or a message\n",
        "            axes[i, j].text(0.5, 0.5, \"Empty Cluster\", ha=\"center\", va=\"center\")\n",
        "\n",
        "        # Add a title with cluster index and size\n",
        "        axes[i, j].set_title(f'Cluster {index}\\nSize: {len(bmu_images)}')\n",
        "\n",
        "        # Remove the axis ticks\n",
        "        axes[i, j].set_xticks([])\n",
        "        axes[i, j].set_yticks([])\n",
        "\n",
        "# Save the figure to a file\n",
        "plt.savefig('grid_som_10x10.png')\n",
        "\n",
        "# Visualize cluster sizes\n",
        "plt.figure()\n",
        "plt.bar(range(m * m), cluster_sizes)\n",
        "plt.xlabel('Cluster Index')\n",
        "plt.ylabel('Cluster Size')\n",
        "plt.title('Cluster Sizes')\n",
        "plt.savefig('cluster_sizes.png')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SfCA_QQR10c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Display 25  images belonging to the target cluster.**"
      ],
      "metadata": {
        "id": "nTe6-9zgUKLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# Target cluster index to display\n",
        "target_cluster = 7  # Change this to the cluster index you want to display\n",
        "##############################################################################\n",
        "\n",
        "\n",
        "\n",
        "# Find all images belonging to the target cluster\n",
        "cluster_images = [filenames[i] for i in range(len(bmu_indices)) if bmu_indices[i][0] == target_cluster]\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "# Limit the display to the first 25 images (you can adjust this number)\n",
        "num_images_to_display = 25\n",
        "##############################################################################\n",
        "cluster_images = cluster_images[:num_images_to_display]\n",
        "\n",
        "# Create a figure to display cluster images\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.suptitle(f\"Cluster {target_cluster} Images (First {num_images_to_display})\", fontsize=16)\n",
        "\n",
        "# Iterate through and display the first 25 images\n",
        "for i in range(len(cluster_images)):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    try:\n",
        "        img = Image.open('/content/drive/MyDrive/Colab Notebooks/streetview/' + cluster_images[i])\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image {i}\")\n",
        "        plt.axis('off')\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image {cluster_images[i]}: {e}\")\n",
        "        plt.text(0.5, 0.5, \"Error\", ha=\"center\", va=\"center\")\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit title\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X74Ys2Ly2qQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z6wZcmxoTDIz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}