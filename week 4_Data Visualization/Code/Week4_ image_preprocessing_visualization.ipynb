{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1U5ins7CY4LrS6qC_BGSdhPAWYBHSTKuj","timestamp":1724181823678}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/sakarla/AI-in-the-Built-Environment/blob/main/week%204_5_Data%20Visualization/Notebook%20code/image_preprocessing_visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["# **Image analysis and preprocessing**\n","In this section, we will implement several preprocessing techniques on the image data. Then we will learn feature extraction and save it in a CSV file. The objective is to familiarize you with essential steps that enhance data clarity, ensuring it is well-prepared for the machine learning process.\n","\n","* Read URLs from JSON or CSV files and show an image\n","* Learn image preprocessing:\n","  *  Resizing\n","  * Grayscale conversion\n","  * Normalization\n","  * Flattening\n","*   Feature extracting from all images and saving into CSV file\n","*  Edge detection\n","\n","Let's get started!"],"metadata":{"id":"0SjrlX6-3-5x"}},{"cell_type":"markdown","source":["# **Read URLs from json or csv file and show image**"],"metadata":{"id":"AsCINFyKs_XH"}},{"cell_type":"markdown","source":["To start, we will link this notebook to your Google Drive. Make sure you are logged in on your Google account"],"metadata":{"id":"_UX705X1nMg1"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab\\ Notebooks\n"],"metadata":{"id":"K6mpZ-3CnLr7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"54e6567f-df1e-4033-8127-9c71e806057f","executionInfo":{"status":"ok","timestamp":1724175842253,"user_tz":240,"elapsed":24772,"user":{"displayName":"Saldana Ochoa, Karla V.","userId":"16000019021450719506"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","\n","############################################################\n","# Specify the folder containing your JSON files\n","folder_path = '/content/drive/MyDrive/Colab Notebooks/myproject/images'\n","############################################################\n","\n","\n","# List all JSON files in the folder\n","json_files = [file for file in os.listdir(folder_path) if file.endswith('.json')]\n","\n","combined_data = []\n","\n","for file in json_files:\n","    with open(os.path.join(folder_path, file), 'r') as f:\n","        data = json.load(f)\n","        combined_data.extend(data)  # or use `.append(data)` for dictionary data\n","\n","############################################################\n","# Save the combined data to a new JSON file\n","\n","# Load the JSON file\n","json_file_path = \"/content/drive/MyDrive/Colab Notebooks/myproject/imagescombined_data.json\"\n","\n","with open(json_file_path, 'w') as f:\n","    json.dump(combined_data, f, indent=4)\n","############################################################\n"],"metadata":{"id":"UiOBEL9H8ntI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To download images from a list of URLs provided in a CSV or JSON file and save them to a designated folder, you can follow this streamlined process:"],"metadata":{"id":"foA-fOe34dNY"}},{"cell_type":"markdown","source":["**Step 1:** Import Libraries\n","\n","Start by importing the necessary libraries:"],"metadata":{"id":"T9QjE30Z4kUu"}},{"cell_type":"code","source":["import pandas as pd  #pandas is a powerful library used for data manipulation and analysis.\n","import requests  #requests is a library for making HTTP requests in Python.\n","import os  #os is a library that provides a way to interact with the operating system.\n","from PIL import Image  #PIL (Python Imaging Library) is a library for opening, manipulating, and saving images.\n"],"metadata":{"id":"7Xec1WxFyZsh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 2:** Read the json File\n","\n","Load the json file containing image URLs using Pandas. Replace \"**content/drive/MyDrive/Colab Notebooks/image/combined_data.json**\" with the actual path to your json file and specify the column containing the image URLs (e.g., \"image_url\")."],"metadata":{"id":"mNXbd2MK4u0V"}},{"cell_type":"code","source":["import json\n","\n","#############################################################################\n","# Initialize an empty list to store the image URLs\n","image_urls = []\n","\n","# Read and parse the JSON file\n","with open(json_file_path, \"r\") as json_file:\n","    data = json.load(json_file)\n","\n","    # Assuming your JSON data is a list of dictionaries with an \"image_url\" field\n","    for item in data:\n","        if \"image_url\" in item:\n","            image_url = item[\"image_url\"]\n","            image_urls.append(image_url)\n","\n","# Now, image_urls contains the image URLs from the JSON data\n","# You can use this list as needed\n"],"metadata":{"id":"GMiyyOR2-gx-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_urls"],"metadata":{"id":"92Xvpcuz-z-o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 3:** Create a Folder to Save Images\n","\n","Create a folder to save the downloaded images if it doesn't already exist. You can specify the folder name as you like."],"metadata":{"id":"c4G5vkE16O_g"}},{"cell_type":"code","source":["output_folder = \"downloaded_images\"\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n"],"metadata":{"id":"Be2TRh224_UV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 4:** Download and Save Images\n","\n","Iterate through the image URLs, download each image, and save it to the folder you created in Step 3."],"metadata":{"id":"qBzkitp86bX-"}},{"cell_type":"code","source":["for i, url in enumerate(image_urls):\n","    try:\n","        response = requests.get(url)\n","        if response.status_code == 200:\n","            image_content = response.content\n","            with open(os.path.join(output_folder, f\"image_{i+1}.jpg\"), \"wb\") as f:\n","                f.write(image_content)\n","            print(f\"Image {i+1} downloaded and saved.\")\n","        else:\n","            print(f\"Failed to download image {i+1}. Status code: {response.status_code}\")\n","    except Exception as e:\n","        print(f\"Error downloading image {i+1}: {str(e)}\")\n"],"metadata":{"id":"X9J0O1Kl6TZ2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code will download the images one by one from the URLs in your JSON file and save them with names like \"image_1.jpg,\" \"image_2.jpg,\" and so on in the specified output folder."],"metadata":{"id":"M6uhSIIT8bTQ"}},{"cell_type":"markdown","source":["**Step 5:** Optional - Display Images\n","\n","If you want to display the downloaded images, you can use the PIL library:"],"metadata":{"id":"dWcHqdbf8evx"}},{"cell_type":"code","source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","#####################################################################################\n","# Specify the file path\n","image_path = '/content/drive/MyDrive/Colab Notebooks/downloaded_images/1.jpg'\n","#####################################################################################\n"],"metadata":{"id":"JMFbzVRj6lAg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if the file exists\n","if os.path.isfile(image_path):\n","    # Open and display the image using Matplotlib\n","    img = Image.open(image_path)\n","    plt.imshow(img)\n","    plt.axis('off')\n","    plt.show()\n","else:\n","    print(f\"Image file not found at: {image_path}\")"],"metadata":{"id":"GJFzn6SuIpE8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Image color processing**\n","This part will guide you through various image color processing techniques using Python. We will use the `cv2` library for image manipulation and `matplotlib` for displaying the images.\n","\n","**Step 1:** Import Libraries and Load the Image\n","\n","Start by importing the necessary libraries and loading the downloaded image:"],"metadata":{"id":"9CL3s-XMEqmE"}},{"cell_type":"code","source":["import cv2\n","import matplotlib.pyplot as plt\n","\n","image = cv2.imread(image_path)\n"],"metadata":{"id":"VjgrT7Je_XXL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 2:** Display the Original Image\n","\n","Display the original image using Matplotlib:"],"metadata":{"id":"QSCBWpdTG3du"}},{"cell_type":"code","source":["plt.figure(figsize=(6, 6))\n","plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB\n","plt.title('Original Image')\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"weh6dKDrE7ku"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, you can perform various image manipulation tasks on this image.\n","\n","**Step 3:** Change Color\n","\n","Change the color of the image by applying a color transformation. For example, let's convert the image to grayscale:"],"metadata":{"id":"SIYXb0PfG_l-"}},{"cell_type":"code","source":["# Convert the image to grayscale\n","gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","# Display the grayscale image\n","plt.figure(figsize=(6, 6))\n","plt.imshow(gray_image, cmap='gray')\n","plt.title('Grayscale Image')\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"_3mrin6-E9uq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 4:** Split Channels\n","\n","You can split the image into its color channels (Red, Green, and Blue) and display each channel separately. Here's an example with the Blue channel:"],"metadata":{"id":"XZMofGLZHIQW"}},{"cell_type":"code","source":["# Split the image into color channels\n","b, g, r = cv2.split(image)\n","\n","# Create a 1x3 grid of subplots for displaying the channels\n","plt.figure(figsize=(18, 6))\n","\n","# Display the Blue channel in the first subplot\n","plt.subplot(131)\n","plt.imshow(b, cmap='Blues')\n","plt.title('Blue Channel')\n","plt.axis('off')\n","\n","# Display the Green channel in the second subplot\n","plt.subplot(132)\n","plt.imshow(g, cmap='Greens')\n","plt.title('Green Channel')\n","plt.axis('off')\n","\n","# Display the Red channel in the third subplot\n","plt.subplot(133)\n","plt.imshow(r, cmap='Reds')\n","plt.title('Red Channel')\n","plt.axis('off')\n","\n","plt.show()\n"],"metadata":{"id":"mGWS5-KuFAKA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 5: Resize Image**\n","\n","Resize the image to a specific size:"],"metadata":{"id":"rNxhCT5lHWw0"}},{"cell_type":"code","source":["image.shape"],"metadata":{"id":"Wo1eNMd5Hgps","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724180022282,"user_tz":240,"elapsed":187,"user":{"displayName":"Saldana Ochoa, Karla V.","userId":"16000019021450719506"}},"outputId":"f4e9a6da-666f-42ed-e435-81664bebb336"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(231, 474, 3)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# Resize the image to a new width and height\n","new_width = 200\n","new_height = 200\n","resized_image = cv2.resize(image, (new_width, new_height))\n","\n","# Display the resized image\n","plt.figure(figsize=(6, 6))\n","plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n","plt.title('Resized Image')\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"WH5AfzIeHZ4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resized_image.shape"],"metadata":{"id":"uJOhPYRWHm4s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724180027710,"user_tz":240,"elapsed":180,"user":{"displayName":"Saldana Ochoa, Karla V.","userId":"16000019021450719506"}},"outputId":"3ca85c64-a88b-4b52-b06f-acc928fc965f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(200, 200, 3)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["**Step 6:** Apply Filters\n","\n","You can apply various filters to the image, such as blurring or sharpening. Here's an example of blurring the image using Gaussian blur:"],"metadata":{"id":"uP7SN9qPHLmF"}},{"cell_type":"code","source":["# Apply Gaussian blur to the original image\n","blurred_image = cv2.GaussianBlur(image, (11, 11), 0)\n","\n","# Create a Matplotlib figure to display the blurred image\n","plt.figure(figsize=(6, 6))\n","\n","# Convert the color format from BGR to RGB for proper display\n","blurred_rgb_image = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB)\n","\n","# Display the blurred RGB image\n","plt.imshow(blurred_rgb_image)\n","\n","# Set a title for the displayed image\n","plt.title('Blurred Image')\n","\n","# Turn off axis labels and ticks for a cleaner display\n","plt.axis('off')\n","\n","# Show the image in the Matplotlib plot\n","plt.show()\n"],"metadata":{"id":"_cPrsme4FqrZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Preprocessing on the entire dataset and Feature Extraction Using Pre-trained Model**\n","In this section, we will preprocess a set of images and extract features using a pre-trained model. Preprocessing involves several steps to ensure the images are in a consistent format, which is crucial for effective feature extraction. We will use the VGG16 model, pre-trained on the ImageNet dataset, to extract meaningful features from the images. These features can be used for various machine learning tasks such as classification, clustering, or image retrieval.\n","\n","**Preprocessing Steps**\n","\n","1. **Loading Images**: We will load the images from the specified directory.\n","2. **Resizing:** Each image will be resized to 224x224 pixels, the input size required by the VGG16 model.\n","3. **Color Conversion:** Images will be converted to RGB format to ensure consistency.\n","4.**Normalization:** Pixel values will be normalized to a range suitable for the model.\n","5. **Error Handling**: Any issues during the image loading and preprocessing will be handled gracefully, ensuring the process continues for the rest of the dataset.\n","\n","**Feature Extraction**\n","\n","1. **Using VGG16 Model:** We will use the VGG16 model, which has been pre-trained on the ImageNet dataset. This model is capable of extracting rich features from images due to its deep architecture and extensive training.\n","2. **Extracting Features:** The model will extract features from the images, which will then be flattened into a one-dimensional array.\n","3. **Saving Features:** The extracted features, along with the corresponding filenames, will be saved to a CSV file for further analysis."],"metadata":{"id":"ofb3SiUxzHr6"}},{"cell_type":"markdown","source":["**Step1:** Load and Preprocess Images"],"metadata":{"id":"diQOsk9j1tki"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n","from tensorflow.keras.preprocessing.image import img_to_array\n","\n","def load_and_preprocess_image(image_path, size=(224, 224)):\n","    try:\n","        # Load the image\n","        img = Image.open(image_path).convert('RGB')  # Ensure the image is in RGB format\n","        # Resize the image\n","        img = img.resize(size)\n","        # Convert the image to an array\n","        img_array = img_to_array(img)\n","        # Expand dimensions to match the shape required by VGG16\n","        img_array = np.expand_dims(img_array, axis=0)\n","        # Preprocess the image for VGG16\n","        img_array = preprocess_input(img_array)\n","        return img_array\n","    except Exception as e:\n","        print(f\"Cannot process image: {image_path}, Error: {e}\")\n","        return None\n","\n","def save_to_csv(data, filename):\n","    # Create DataFrame\n","    df = pd.DataFrame(data)\n","    # Save to CSV\n","    df.to_csv(filename, index=False)\n","\n","#########################################################\n","# Directory where your images are stored\n","image_dir = '/content/drive/MyDrive/Colab Notebooks/downloaded_images'\n","\n","#########################################################\n","image_paths = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.jpg')]\n"],"metadata":{"id":"3xa4yNSuzGzS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 2:** Feature Extraction Using Pre-trained Model"],"metadata":{"id":"0xJDDcfT15vC"}},{"cell_type":"code","source":["# Load the VGG16 model pre-trained on ImageNet\n","vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","def extract_features(image_paths, model):\n","    features = []\n","    for path in image_paths:\n","        img_array = load_and_preprocess_image(path)\n","        if img_array is not None:\n","            try:\n","                # Extract features using VGG16\n","                feature = model.predict(img_array)\n","                # Flatten the feature map\n","                feature = feature.flatten()\n","                features.append({'FileName': os.path.basename(path), 'Features': feature.tolist()})\n","            except Exception as e:\n","                print(f\"Error extracting features from image: {path}, Error: {e}\")\n","    return features\n","\n","# Extract features for all images\n","image_features = extract_features(image_paths, vgg16_model)\n","\n","#########################################################\n","# Save the features to CSV\n","save_to_csv(image_features, 'image_features_vgg16.csv')\n","\n","#########################################################"],"metadata":{"id":"jiKPuMKl1x4p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Edge Detection**\n","\n","Edge detection is a technique used in image processing and computer vision to identify the boundaries or edges within an image. These edges represent significant changes in intensity or color and often correspond to the boundaries of objects within the image. Detecting these edges is crucial for understanding the structure of objects and scenes in the image.\n","\n","To perform edge detection on an image in Python, you can use the popular library OpenCV. Here are the steps to perform edge detection on the image you downloaded:"],"metadata":{"id":"-ph5DzWy-iOk"}},{"cell_type":"markdown","source":["**Step 1:** Import Libraries\n","\n","Start by importing the necessary libraries:"],"metadata":{"id":"PfyJX_h3-sqs"}},{"cell_type":"code","source":["import cv2\n","import matplotlib.pyplot as plt\n"],"metadata":{"id":"zmPdZlZY8jda"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Make sure you have OpenCV installed in your Colab environment. You can install it using `!pip install opencv-python` if it's not already installed."],"metadata":{"id":"Xh36iy0W-yo2"}},{"cell_type":"markdown","source":["**Step 2:** Load the Image\n","\n","Load the downloaded image using OpenCV:"],"metadata":{"id":"Ro5pu3LT-5qn"}},{"cell_type":"code","source":["########################################################\n","image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n"],"metadata":{"id":"5VPObHxt-v-0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `cv2.IMREAD_GRAYSCALE `flag loads the image in grayscale mode, which simplifies edge detection."],"metadata":{"id":"UR0dvnyD_Ez7"}},{"cell_type":"markdown","source":["**Step 3:** Perform Edge Detection\n","\n","The Canny edge detection algorithm is a multi-step process. It is widely used in computer vision and image processing due to its ability to detect a wide range of edges in images. The algorithm is designed to be robust to noise and to find the most significant edges in an image.\n","\n","Perform edge detection on the loaded image using the Canny edge detection algorithm:"],"metadata":{"id":"OaD_1XWL_JMf"}},{"cell_type":"code","source":["edges = cv2.Canny(image, threshold1=30, threshold2=100)\n"],"metadata":{"id":"C2R3PVOE-80s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can adjust the threshold1 and threshold2 parameters to control the sensitivity of edge detection. These values determine the lower and upper thresholds for edge detection."],"metadata":{"id":"0Wi6rjsS_ROl"}},{"cell_type":"markdown","source":["**Step 4:** Display the Original Image and Edge Image\n","\n","Display both the original image and the edge-detected image using Matplotlib:"],"metadata":{"id":"MuKZ6-qm_Tlt"}},{"cell_type":"code","source":["# Display the original image\n","plt.figure(figsize=(10, 10))\n","plt.subplot(121)\n","plt.imshow(image, cmap='gray')\n","plt.title('Original Image')\n","plt.axis('off')\n","\n","# Display the edge-detected image\n","plt.subplot(122)\n","plt.imshow(edges, cmap='gray')\n","plt.title('Edge Detection')\n","plt.axis('off')\n","\n","plt.show()\n"],"metadata":{"id":"oXO4_n00_No8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Save Feature extracted from edge detection in csv file**"],"metadata":{"id":"8JUOoAmjtWRd"}},{"cell_type":"markdown","source":["This part will guide you through extracting features from edge-detected images and saving these features in a CSV file using Python."],"metadata":{"id":"mj6JgPg1CoGm"}},{"cell_type":"code","source":["import cv2\n","import csv\n","import numpy as np\n","\n","def extract_features(image_path):\n","    # Check if the image file exists\n","    if not os.path.exists(image_path):\n","        return None, \"File not found\"\n","\n","    # Read the image\n","    image = cv2.imread(image_path)\n","\n","    # Check if the image was loaded successfully\n","    if image is None:\n","        return None, \"Image not loaded\"\n","    # Convert to grayscale\n","    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    # Resize image if necessary\n","    resized_image = cv2.resize(gray_image, (width, height))  # Define width and height\n","    # Perform edge detection\n","    edges = cv2.Canny(resized_image, threshold1=30, threshold2=100)\n","    # Flatten the edge image to create a feature vector\n","    feature_vector = edges.flatten()\n","    return feature_vector\n","\n","\n","width=28\n","height=28\n","# List of image file paths\n","image_paths = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.jpg')]\n","# List to hold all feature vectors\n","feature_vectors = []\n","\n","# Open the CSV file for writing\n","with open('feature_vectors_edge.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    # Write the header\n","    writer.writerow(['image_name', 'features'])\n","\n","    # Extract features for each image and write to the CSV file\n","    for path in image_paths:\n","        features = extract_features(path)\n","        # Write the image name and feature string to the CSV\n","        writer.writerow([path, features])"],"metadata":{"id":"luJSkl92R2hj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Save just preprocessing**"],"metadata":{"id":"kWqoB8UGNhMD"}},{"cell_type":"markdown","source":["You can do some preprocessing steps for all images and save in csv file. because it good to do not repeat every time."],"metadata":{"id":"Fjr_JjUsKsF5"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","import pandas as pd\n","\n","def load_and_preprocess_image(image_path, size=(64, 64)):\n","    try:\n","        # Load the image\n","        img = Image.open(image_path)\n","        # Resize and convert to grayscale\n","        img = img.resize(size).convert('L')\n","        # Normalize and flatten\n","        image_data = np.array(img).flatten() / 255.0\n","        # Get file name\n","        file_name = os.path.basename(image_path)\n","        return file_name, image_data\n","    except IOError:\n","        print(f\"Cannot process image: {image_path}\")\n","        return None\n","\n","def save_to_csv(data, filename):\n","    # Remove None values\n","    data = [d for d in data if d is not None]\n","    # Create DataFrame\n","    df = pd.DataFrame(data, columns=['FileName', 'ImageData'])\n","    # Save to CSV\n","    df.to_csv(filename, index=False)\n","#########################################################################\n","# Directory where your images are stored\n","image_dir = '/content/drive/MyDrive/Colab Notebooks/downloaded_images'\n","#########################################################################\n","\n","image_paths = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.jpg')]\n","\n","# Process each image and store in a list\n","processed_images = [load_and_preprocess_image(path) for path in image_paths]\n","\n","# Save to CSV\n","save_to_csv(processed_images, 'preprocessed_images.csv')\n"],"metadata":{"id":"YivDAvtaIw6D"},"execution_count":null,"outputs":[]}]}